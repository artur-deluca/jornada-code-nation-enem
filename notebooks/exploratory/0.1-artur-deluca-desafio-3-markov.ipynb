{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Rebuild ENEM's answers<br></h3>\n",
    "\n",
    "The enem's math test consists of 45 single choice questions with alternatives ranging from A to E. In this scenario the last five answers have been removed from the test dataset, so you will rebuild them from the final average result - creating a model to predict the marked down answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.send_answer import send_answer\n",
    "from src.models.markov import Markov\n",
    "from src.models.score import score, naive_approach\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the available options to choose from (A to E) and including the possibility to leave the question blank (*) the student last 5 answers would have a 1/7776 probability in a uniform distribution.<br><br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "train = pd.read_csv('../../data/interim/train3.csv').set_index('NU_INSCRICAO')\n",
    "validation = pd.read_csv('../../data/interim/validation3.csv').set_index('NU_INSCRICAO')\n",
    "test = pd.read_csv('../../data/interim/test3.csv').set_index('NU_INSCRICAO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy\n",
    "The strategy to overcome the dataset diversity consists on segmenting data in subsets in which the likelihood of similar answers gets increased. Not only segmenting the dataset by the **types of tests employed**, but by **using the model defined in the previous challenge to recreate the math grades**, we may better segment the dataset. By **using quantiles to classify the grades** is possible to create a new category of segregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of previous answers to take in account to predict the next values\n",
    "order = 3\n",
    "\n",
    "# number of answers to predict per row\n",
    "streak = 5\n",
    "\n",
    "# target to predict\n",
    "target = 'TX_RESPOSTAS_MT'\n",
    "\n",
    "# fields to segment the dataset\n",
    "id = ['CO_PROVA_MT', 'NU_NOTA_MT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Estimate</h3><br>\n",
    "The underlying idea of the following function is to predict written answer for the segmented performance quantile as well as for its corresponding test using a Markov Chain.<br>\n",
    "\n",
    "*Reference materials:*\n",
    "<ol>\n",
    "    <li><a href=\"https://www.youtube.com/watch?v=eGFJ8vugIWA\">Coding Train - Markov Chains</a></li>\n",
    "    <li><a href=\"http://setosa.io/ev/markov-chains/\">Markov Chains Visually Explained</a></li>\n",
    "</ol>\n",
    "\n",
    "<br>In this case, the Markov Chain will be trained with the last 3 predecessors of the first answer to predict along with the answers of the trained dataset. The prediction will then identify the last three elements of the input to estimate the next 5 answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Markov(order, streak, target, id)\n",
    "model.train_chain(train, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = {\n",
    "    'train': lambda df, id, target: model.predict(df[target][-(order+streak):-streak], tuple(df.loc[id].values)),\n",
    "    'test': lambda df, id, target: model.predict(df[target][-order:], tuple(df.loc[id].values))\n",
    "}\n",
    "\n",
    "\n",
    "train['PREDICTION'] = train.apply(predict['train'], id=id, target=target, axis=1)\n",
    "\n",
    "validation['PREDICTION'] = validation.apply(predict['train'], id=id, target=target, axis=1)\n",
    "\n",
    "test['PREDICTION'] = test.apply(predict['test'], id=id, target=target, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```order = 3```\n",
    "\n",
    "The order of the Markov Chain in this case is crucial to the success of the model. A small order can result in a very random guess by the estimator as well as a very large order can result in a strongly biased model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 58.55\n",
      "Validation set accuracy: 22.73\n",
      "Naive approach accuracy: 20.06\n"
     ]
    }
   ],
   "source": [
    "print('Training set accuracy: %.2f' % (score(train.TX_RESPOSTAS_MT.str[-streak:], train.PREDICTION)*100))\n",
    "print('Validation set accuracy: %.2f' % (score(validation.TX_RESPOSTAS_MT.str[-streak:], validation.PREDICTION)*100))\n",
    "print('Naive approach accuracy: %.2f' % (naive_approach(validation)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is plausible to infer, by observing the train and validation results, that the Markov chain is very conditioned to the trained results, thus implying in a overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Send answers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = test.copy().loc[:,['PREDICTION']]\n",
    "answer = answer.rename(index=str, columns={\"PREDICTION\": \"TX_RESPOSTAS_MT\"})\n",
    "#send_answer(answer.reset_index(), 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

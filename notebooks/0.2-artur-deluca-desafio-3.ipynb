{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Rebuild ENEM's answers<br></h3>\n",
    "\n",
    "The enem's test with 45 single choice math questions, followed by alternatives ranging from A to E. In this scenario the last five answers have been removed from the test dataset, so you will rebuild them from the final average result - creating a model to predict the marked down answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.send_answer import send_answer\n",
    "from src.models.regression import predict\n",
    "from src.models.score import score\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "train = pd.read_csv('../data/raw/train.csv', index_col=0).set_index('NU_INSCRICAO')\n",
    "test = pd.read_csv('../data/raw/test3.csv').set_index('NU_INSCRICAO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Strategy</h3><br>\n",
    "Considering the available options to choose from (A to E) and including the possibility to leave the question blank (*) the student last 5 answers would have a 1/7776 probability in a uniform distribution.<br><br> The strategy to overcome the dataset diversity consists on segmenting data in subsets in which the likelihood of similar answers gets increased. Not only segmenting the dataset by the types of tests employed, but by using the model defined in the previous challenge to recreate the math grades, we may better segment the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick data clean-up\n",
    "train.loc[:, 'TX_RESPOSTAS_MT'] = train.loc[:, 'TX_RESPOSTAS_MT'].str.replace('\\.', '*')\n",
    "train = train.loc[train.TX_RESPOSTAS_MT.dropna(axis=0).index]\n",
    "\n",
    "# predict the grades on the test set using the Quantile Transformation\n",
    "grade_prediction = predict(train.drop('TX_RESPOSTAS_MT', axis=1), test.drop('TX_RESPOSTAS_MT', axis=1))\n",
    "test.loc[list(grade_prediction.index), 'NU_NOTA_MT'] = grade_prediction.loc[:,'NU_NOTA_MT']\n",
    "\n",
    "# remove the 0 scores from the training set\n",
    "train = train.loc[train.NU_NOTA_MT != 0,:]\n",
    "\n",
    "# reposition the training set\n",
    "train = train.copy()[list(test.columns)+['TX_GABARITO_MT']]\n",
    "\n",
    "# separte the datasets in quartiles based on the math grade\n",
    "quartiles = 4\n",
    "merged_grades = pd.qcut(pd.concat([train.NU_NOTA_MT, test.NU_NOTA_MT]), quartiles, labels = False)\n",
    "train['MT_QT'] = merged_grades.loc[train.index].values\n",
    "test['MT_QT'] = merged_grades.loc[test.index].values\n",
    "\n",
    "\n",
    "train['PREDICTION'] = ''\n",
    "test['PREDICTION'] = '' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Estimate</h3><br>\n",
    "The underlying idea of the following function is to predict written answer for the segmented performance quartile as well as for its corresponding test using a Markov Chain.<br>\n",
    "\n",
    "*Reference materials:*\n",
    "<ol>\n",
    "    <li><a href=\"https://www.youtube.com/watch?v=eGFJ8vugIWA\">Coding Train - Markov Chains</a></li>\n",
    "    <li><a href=\"http://setosa.io/ev/markov-chains/\">Markov Chains Visually Explained</a></li>\n",
    "</ol>\n",
    "\n",
    "<br>In this case, the Markov Chain will be trained with the last 3 predecessors of the first answer to predict along with the answers of the trained dataset. The prediction of the chain will happen incrementally, as it predicts the answers one by one \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Markov:\n",
    "    def __init__(self, order = 3):\n",
    "        \n",
    "        self.states = {}\n",
    "        self.order = order\n",
    "    \n",
    "    def train(self, elements):\n",
    "        for i in range(len(elements)):\n",
    "            # create the keys based on the order of the Markov Chain            \n",
    "            key = tuple(elements[i:self.order+i])\n",
    "            if key not in self.states.keys():\n",
    "                self.states[key] = []\n",
    "            try:\n",
    "                self.states[key].append(elements[self.order+i])\n",
    "            except IndexError:\n",
    "                pass\n",
    "    \n",
    "    def predict(self, elements):\n",
    "        try:\n",
    "            return np.random.choice(self.states[tuple(elements[-self.order:])])\n",
    "        except ValueError:\n",
    "            raise KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning set accuracy: 23.42%\n"
     ]
    }
   ],
   "source": [
    "# set up the variables for the Markov Chains\n",
    "\n",
    "# number of letters considered to train the Markov Chain (e.g. Reads the last three answer to predict the next)\n",
    "order = 3 \n",
    "n_predictions = 5\n",
    "shift = n_predictions + order\n",
    "\n",
    "# iterate through all the math test codes in the training set\n",
    "test_codes = train.CO_PROVA_MT.unique()\n",
    "for cod in test_codes:\n",
    "    \n",
    "    # iterate through the performance quartiles\n",
    "    grade_quartiles = train.MT_QT.unique()\n",
    "    for quartile in grade_quartiles:\n",
    "       \n",
    "        model = Markov(order)\n",
    "        # train markov chain using each line\n",
    "        \n",
    "        train_set = train.loc[(train.CO_PROVA_MT == cod) & (train.MT_QT == quartile)]\n",
    "        test_set = test.loc[(test.CO_PROVA_MT == cod) & (test.MT_QT == quartile)]\n",
    "        \n",
    "        train_test_set = pd.concat([\n",
    "            train_set.loc[:,'TX_RESPOSTAS_MT'].str[-shift:-n_predictions], \n",
    "            test_set.loc[:,'TX_RESPOSTAS_MT'].str[-order:]\n",
    "        ])\n",
    "        \n",
    "        for i in train_set['TX_RESPOSTAS_MT'].str[-shift:]:\n",
    "            model.train(i)\n",
    "            # attempt to enforce higher grades\n",
    "            #for _ in range(int(quartile)):\n",
    "            #    model.train(train.loc[i,'TX_GABARITO_MT'][-shift:])\n",
    "              \n",
    "        for index, element in train_test_set.iteritems():\n",
    "            # build answer from empty string\n",
    "            enem_answer = ''\n",
    "            for _ in range(n_predictions):\n",
    "                try:\n",
    "                    enem_answer += model.predict(element)\n",
    "                except KeyError or ValueError:\n",
    "                    # In case it tries to make an unseen prediction, the result will be the mode on that position\n",
    "                    enem_answer += train_set.loc[:, 'TX_RESPOSTAS_MT'].str[-n_predictions+len(enem_answer)].mode()[0]\n",
    "                element = element[-order+1:]+enem_answer[-1]\n",
    "            train_test_set.loc[index] = enem_answer\n",
    "        \n",
    "        train.loc[train_set.index,'PREDICTION'] = train_test_set.loc[train_set.index]\n",
    "        test.loc[test_set.index,'PREDICTION'] = train_test_set.loc[test_set.index]\n",
    "\n",
    "print('Traning set accuracy: {:.2f}%'.format(score(train.TX_RESPOSTAS_MT.str[-n_predictions:], train.PREDICTION)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of the Markov Chain in this case is crucial to the success of the model. A small order can result in a very random guess by the estimator as well as a very large order can result in a strongly biased model, causing an overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = test.copy().loc[:,['PREDICTION']]\n",
    "answer = answer.rename(index=str, columns={\"PREDICTION\": \"TX_RESPOSTAS_MT\"})\n",
    "#send_answer(answer.reset_index(), 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
